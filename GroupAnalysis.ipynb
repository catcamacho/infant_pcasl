{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group Level Analysis\n",
    "\n",
    "This notebook is designed to perform a voxelwise analysis of the infant CBF data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nipype.interfaces.utility import Function, IdentityInterface\n",
    "from nipype.interfaces.io import SelectFiles, DataSink, DataGrabber\n",
    "from nipype.pipeline.engine import Workflow, Node, MapNode\n",
    "from nipype.interfaces.fsl.utils import Merge\n",
    "from nipype.interfaces.fsl.model import Randomise, Cluster\n",
    "from nipype.interfaces.fsl.maths import ApplyMask\n",
    "\n",
    "# FSL set up- change default file output type\n",
    "from nipype.interfaces.fsl import FSLCommand\n",
    "FSLCommand.set_default_output_type('NIFTI_GZ')\n",
    "\n",
    "#other study-specific variables\n",
    "#project_home = '/Volumes/iang/active/BABIES/BABIES_perfusion'\n",
    "project_home = '/Users/catcamacho/Box/SNAP/BABIES'\n",
    "output_dir = project_home + '/proc/asl_group'\n",
    "preproc_dir = project_home + '/proc/asl_preproc'\n",
    "wkflow_dir = project_home + '/workflows'\n",
    "template = project_home + '/templates/T2w_BABIES_template_2mm.nii.gz'\n",
    "mask = project_home + '/templates/BABIES_gm_mask_2mm.nii.gz'\n",
    "\n",
    "# Files for group level analysis\n",
    "group_mat = project_home + '/misc/design_factors.mat'\n",
    "t_contrasts = project_home + '/misc/tcon_factors.con'\n",
    "\n",
    "subjects_list = open(project_home + '/misc/subjects_asl.txt').read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Handling Nodes\n",
    "\n",
    "datasink = Node(DataSink(), name='datasink')\n",
    "datasink.inputs.base_directory = output_dir\n",
    "datasink.inputs.container = output_dir\n",
    "\n",
    "grabcbfdata = Node(DataGrabber(template=preproc_dir + '/cbf_volume/*/salsop_cbf_masked.nii.gz', \n",
    "                               sort_filelist=True, \n",
    "                               outfields=['cbf_list']), \n",
    "                   name='grabcbf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cluster_peaks(clusters_file, stat_file):\n",
    "    from nibabel import load, save, Nifti1Image\n",
    "    from pandas import DataFrame, Series\n",
    "    from numpy import unique, unravel_index, max\n",
    "    from os.path import abspath\n",
    "    \n",
    "    # load up clusters\n",
    "    clusters_nii = load(clusters_file)\n",
    "    clusters_data = clusters_nii.get_data()\n",
    "    cluster_labels, cluster_sizes = unique(clusters_data, return_counts=True)\n",
    "    cluster_sizes = cluster_sizes[cluster_labels>0]\n",
    "    cluster_labels = cluster_labels[cluster_labels>0]\n",
    "    \n",
    "    # set up dataframe\n",
    "    cluster_info = DataFrame(columns=['clust_num','peak','num_voxels','X','Y','Z'])\n",
    "    cluster_info['clust_num'] = Series(cluster_labels,index=None)\n",
    "    \n",
    "    for i in range(0,len(cluster_labels)):\n",
    "        # load up stat image\n",
    "        stat_nii = load(stat_file)\n",
    "        stat_data = stat_nii.get_data()\n",
    "        stat_data[clusters_data!=cluster_labels[i]]=0\n",
    "        location=unravel_index(stat_data.argmax(), stat_data.shape)\n",
    "        cluster_info.iloc[i,0]=cluster_labels[i]\n",
    "        cluster_info.iloc[i,1]=max(stat_data)\n",
    "        cluster_info.iloc[i,2]=cluster_sizes[i]\n",
    "        cluster_info.iloc[i,3]=location[0]\n",
    "        cluster_info.iloc[i,4]=location[1]\n",
    "        cluster_info.iloc[i,5]=location[2]\n",
    "    \n",
    "    out_prefix = clusters_file[:-7]\n",
    "    cluster_info.to_csv(out_prefix + '_peaks.csv')\n",
    "    cluster_info_file = abspath(out_prefix + '_peaks.csv')\n",
    "    return(cluster_info_file)\n",
    "\n",
    "def extract_cluster_betas(cluster_index_file, sample_betas, min_clust_size, subject_ids):\n",
    "    from nibabel import load, save, Nifti1Image\n",
    "    from pandas import DataFrame, Series\n",
    "    from numpy import unique, zeros_like, invert\n",
    "    from nipype.interfaces.fsl.utils import ImageMeants\n",
    "    from os.path import abspath, basename\n",
    "    \n",
    "    subject_ids = sorted(subject_ids)\n",
    "    sample_data = DataFrame(subject_ids, index=None, columns=['Subject'])\n",
    "    \n",
    "    cluster_nifti = load(cluster_index_file)\n",
    "    cluster_data = cluster_nifti.get_data()\n",
    "    clusters, cluster_sizes = unique(cluster_data, return_counts=True)\n",
    "    cluster_sizes = cluster_sizes[clusters>0]\n",
    "    clusters = clusters[clusters>0]\n",
    "    clusters = clusters[cluster_sizes>min_clust_size]\n",
    "    cluster_sizes = cluster_sizes[cluster_sizes>min_clust_size]\n",
    "    ind_filename = basename(cluster_index_file) \n",
    "    out_prefix = ind_filename[:-7]\n",
    "    \n",
    "    for clust_idx in clusters:\n",
    "        temp = zeros_like(cluster_data)\n",
    "        temp[cluster_data==clust_idx] = 1\n",
    "        temp_nii = Nifti1Image(temp,cluster_nifti.affine)\n",
    "        temp_file = 'temp_clust_mask.nii.gz'\n",
    "        save(temp_nii, temp_file)\n",
    "\n",
    "        eb = ImageMeants()\n",
    "        eb.inputs.in_file = sample_betas\n",
    "        eb.inputs.mask = temp_file\n",
    "        eb.inputs.out_file = 'betas.txt'\n",
    "        eb.run()\n",
    "        betas = open('betas.txt').read().splitlines()\n",
    "        sample_data['clust' + str(clust_idx)] = Series(betas, index=sample_data.index)\n",
    "    \n",
    "    sample_data.to_csv(out_prefix+'_extracted_betas.csv')\n",
    "    extracted_betas_csv = abspath(out_prefix+'_extracted_betas.csv')\n",
    "\n",
    "    return(extracted_betas_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis Nodes\n",
    "\n",
    "merge = Node(Merge(dimension = 't'), name = 'merge')\n",
    "\n",
    "apply_mask = Node(ApplyMask(mask_file=mask, nan2zeros=True), name='apply_mask')\n",
    "\n",
    "randomise = Node(Randomise(tfce = False,\n",
    "                           num_perm = 500,\n",
    "                           tcon = t_contrasts,\n",
    "                           demean = True,\n",
    "                           design_mat = group_mat), name = 'randomise')\n",
    "\n",
    "cluster = MapNode(Cluster(out_localmax_txt_file = 'cluster_stats.txt',\n",
    "                          threshold=2.48, \n",
    "                          out_index_file='clusters.nii.gz'), \n",
    "                  name='cluster', iterfield=['in_file'])\n",
    "\n",
    "get_peaks = MapNode(Function(input_names=['clusters_file', 'stat_file'], \n",
    "                             output_names=['cluster_info_file'], \n",
    "                             function=get_cluster_peaks), \n",
    "                    name='get_peaks', iterfield=['clusters_file', 'stat_file'])\n",
    "\n",
    "get_betas = MapNode(Function(input_names=['cluster_index_file', 'sample_betas', \n",
    "                                          'min_clust_size', 'subject_ids'], \n",
    "                             output_names=['extracted_betas_csv'], \n",
    "                             function=extract_cluster_betas), \n",
    "                    name='get_betas', iterfield=['cluster_index_file'])\n",
    "get_betas.inputs.subject_ids = subjects_list\n",
    "get_betas.inputs.min_clust_size=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis workflow\n",
    "\n",
    "grouplevel = Workflow(name='grouplevel')\n",
    "\n",
    "grouplevel.connect([(grabcbfdata, merge,[('cbf_list', 'in_files')]),\n",
    "                    (merge, apply_mask, [('merged_file','in_file')]),\n",
    "                    (apply_mask, randomise, [('out_file', 'in_file')]),\n",
    "                    (randomise, cluster, [('tstat_files','in_file')]),\n",
    "                    (cluster, get_peaks, [('index_file','clusters_file')]),\n",
    "                    (randomise, get_peaks, [('tstat_files','stat_file')]),\n",
    "                    (cluster, get_betas ,[('index_file','cluster_index_file')]),\n",
    "                    (merge, get_betas, [('merged_file','sample_betas')]),\n",
    "                    \n",
    "                    (get_peaks, datasink, [('cluster_info_file','cluster_stats')]),\n",
    "                    (cluster, datasink, [('index_file','cluster_file')]),\n",
    "                    (get_betas, datasink, [('extracted_betas_csv','cluster_betas')]),\n",
    "                    (randomise, datasink, [('t_corrected_p_files', 'factors_t_corrected_p_files')]),\n",
    "                    (randomise, datasink, [('tstat_files', 'factors_tstat_files')])\n",
    "                   ])\n",
    "\n",
    "grouplevel.base_dir = wkflow_dir\n",
    "grouplevel.write_graph(graph2use='flat')\n",
    "grouplevel.run('MultiProc', plugin_args={'n_procs': 2})\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
