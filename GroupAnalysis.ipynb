{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group Level Analysis\n",
    "\n",
    "This notebook is designed to perform a voxelwise analysis of the infant CBF data and produces summary reports of the cluster statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nipype.interfaces.utility import Function, IdentityInterface\n",
    "from nipype.interfaces.io import SelectFiles, DataSink, DataGrabber\n",
    "from nipype.pipeline.engine import Workflow, Node, MapNode\n",
    "from nipype.interfaces.fsl.utils import Merge, Split\n",
    "from nipype.interfaces.fsl.model import Randomise, Cluster, GLM\n",
    "from nipype.interfaces.fsl.maths import ApplyMask\n",
    "\n",
    "# FSL set up- change default file output type\n",
    "from nipype.interfaces.fsl import FSLCommand\n",
    "FSLCommand.set_default_output_type('NIFTI_GZ')\n",
    "\n",
    "#other study-specific variables\n",
    "#project_home = '/Volumes/iang/active/BABIES/BABIES_perfusion'\n",
    "project_home = '/Users/catcamacho/Box/SNAP/BABIES/BABIES_asl'\n",
    "template_dir = '/Users/catcamacho/Box/SNAP/BABIES/templates'\n",
    "output_dir = project_home + '/proc/asl_group_age'\n",
    "preproc_dir = project_home + '/proc/asl_preproc'\n",
    "wkflow_dir = project_home + '/workflows'\n",
    "template = template_dir + '/6mo_T2w_template_2mm.nii.gz'\n",
    "mask = template_dir + '/6mo_T2w_template_2mm_gm.nii.gz'\n",
    "\n",
    "# Files for group level analysis\n",
    "group_mat = project_home + '/misc/design_age.mat'\n",
    "t_contrasts = project_home + '/misc/tcon_age.con'\n",
    "\n",
    "subjects_list = open(project_home + '/misc/subjects_asl.txt').read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Handling Nodes\n",
    "\n",
    "datasink = Node(DataSink(), name='datasink')\n",
    "datasink.inputs.base_directory = output_dir\n",
    "datasink.inputs.container = output_dir\n",
    "\n",
    "grabcbfdata = Node(DataGrabber(template=preproc_dir + '/cbf_volume/*/salsop_cbf_masked.nii.gz', \n",
    "                               sort_filelist=True, \n",
    "                               outfields=['cbf_list']), \n",
    "                   name='grabcbf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cluster_peaks(clusters_file, stat_file):\n",
    "    '''This function takes an FSL cluster output file (cluster_file; a nifti with numbered cluster \n",
    "    masks) and the statistical map from the group level analysis (stat_file; a nifti file) produces \n",
    "    a csv summary of the cluster statistics inluding the extent and peak statistic(cluster_info_file).'''\n",
    "    from nibabel import load, save, Nifti1Image\n",
    "    from pandas import DataFrame, Series\n",
    "    from numpy import unique, unravel_index, max\n",
    "    from os.path import abspath\n",
    "    \n",
    "    # load up clusters\n",
    "    clusters_nii = load(clusters_file)\n",
    "    clusters_data = clusters_nii.get_data()\n",
    "    cluster_labels, cluster_sizes = unique(clusters_data, return_counts=True)\n",
    "    cluster_sizes = cluster_sizes[cluster_labels>0]\n",
    "    cluster_labels = cluster_labels[cluster_labels>0]\n",
    "    \n",
    "    # set up dataframe\n",
    "    cluster_info = DataFrame(columns=['clust_num','peak','num_voxels','X','Y','Z'])\n",
    "    cluster_info['clust_num'] = Series(cluster_labels,index=None)\n",
    "    \n",
    "    for i in range(0,len(cluster_labels)):\n",
    "        # load up stat image\n",
    "        stat_nii = load(stat_file)\n",
    "        stat_data = stat_nii.get_data()\n",
    "        stat_data[clusters_data!=cluster_labels[i]]=0\n",
    "        location=unravel_index(stat_data.argmax(), stat_data.shape)\n",
    "        cluster_info.iloc[i,0]=cluster_labels[i]\n",
    "        cluster_info.iloc[i,1]=max(stat_data)\n",
    "        cluster_info.iloc[i,2]=cluster_sizes[i]\n",
    "        cluster_info.iloc[i,3]=location[0]\n",
    "        cluster_info.iloc[i,4]=location[1]\n",
    "        cluster_info.iloc[i,5]=location[2]\n",
    "    \n",
    "    out_prefix = clusters_file[:-7]\n",
    "    cluster_info.to_csv(out_prefix + '_peaks.csv')\n",
    "    cluster_info_file = abspath(out_prefix + '_peaks.csv')\n",
    "    return(cluster_info_file)\n",
    "\n",
    "def extract_cluster_betas(cluster_index_file, sample_betas, min_clust_size, subject_ids):\n",
    "    '''This function extracts the subject-level data that was inputted into the group-level \n",
    "    analysis on a cluster-wise basis.'''\n",
    "    from nibabel import load, save, Nifti1Image\n",
    "    from pandas import DataFrame, Series\n",
    "    from numpy import unique, zeros_like, invert\n",
    "    from nipype.interfaces.fsl.utils import ImageMeants\n",
    "    from os.path import abspath, basename\n",
    "    \n",
    "    sample_data = DataFrame(subject_ids, index=None, columns=['Subject'])\n",
    "    \n",
    "    cluster_nifti = load(cluster_index_file)\n",
    "    cluster_data = cluster_nifti.get_data()\n",
    "    clusters, cluster_sizes = unique(cluster_data, return_counts=True)\n",
    "    cluster_sizes = cluster_sizes[clusters>0]\n",
    "    clusters = clusters[clusters>0]\n",
    "    clusters = clusters[cluster_sizes>min_clust_size]\n",
    "    cluster_sizes = cluster_sizes[cluster_sizes>min_clust_size]\n",
    "    ind_filename = basename(cluster_index_file) \n",
    "    out_prefix = ind_filename[:-7]\n",
    "    \n",
    "    for clust_idx in clusters:\n",
    "        temp = zeros_like(cluster_data)\n",
    "        temp[cluster_data==clust_idx] = 1\n",
    "        temp_nii = Nifti1Image(temp,cluster_nifti.affine)\n",
    "        temp_file = 'temp_clust_mask.nii.gz'\n",
    "        save(temp_nii, temp_file)\n",
    "\n",
    "        eb = ImageMeants()\n",
    "        eb.inputs.in_file = sample_betas\n",
    "        eb.inputs.mask = temp_file\n",
    "        eb.inputs.out_file = 'betas.txt'\n",
    "        eb.run()\n",
    "        betas = open('betas.txt').read().splitlines()\n",
    "        sample_data['clust' + str(clust_idx)] = Series(betas, index=sample_data.index)\n",
    "    \n",
    "    sample_data.to_csv(out_prefix+'_extracted_betas.csv')\n",
    "    extracted_betas_csv = abspath(out_prefix+'_extracted_betas.csv')\n",
    "\n",
    "    return(extracted_betas_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis Nodes\n",
    "\n",
    "merge = Node(Merge(dimension = 't'), name = 'merge')\n",
    "\n",
    "apply_mask = Node(ApplyMask(mask_file=mask, nan2zeros=True), name='apply_mask')\n",
    "\n",
    "model = Node(GLM(design=group_mat, mask=mask, \n",
    "                 out_p_name='pvals.nii.gz',\n",
    "                 out_t_name='tstat.nii.gz', \n",
    "                 contrasts=t_contrasts), \n",
    "             name='model')\n",
    "\n",
    "split = Node(Split(dimension='t'), name='split')\n",
    "\n",
    "cluster = MapNode(Cluster(out_localmax_txt_file = 'cluster_stats.txt',\n",
    "                          threshold=3.3256, \n",
    "                          dlh=4, \n",
    "                          pthreshold=0.01, \n",
    "                          volume=113120,\n",
    "                          out_index_file='clusters.nii.gz'), \n",
    "                  name='cluster', iterfield=['in_file'])\n",
    "\n",
    "get_peaks = MapNode(Function(input_names=['clusters_file', 'stat_file'], \n",
    "                             output_names=['cluster_info_file'], \n",
    "                             function=get_cluster_peaks), \n",
    "                    name='get_peaks', iterfield=['clusters_file', 'stat_file'])\n",
    "\n",
    "get_betas = MapNode(Function(input_names=['cluster_index_file', 'sample_betas', \n",
    "                                          'min_clust_size', 'subject_ids'], \n",
    "                             output_names=['extracted_betas_csv'], \n",
    "                             function=extract_cluster_betas), \n",
    "                    name='get_betas', iterfield=['cluster_index_file'])\n",
    "get_betas.inputs.subject_ids = subjects_list\n",
    "get_betas.inputs.min_clust_size=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis workflow\n",
    "\n",
    "grouplevel = Workflow(name='grouplevel_age_sex')\n",
    "\n",
    "grouplevel.connect([(grabcbfdata, merge,[('cbf_list', 'in_files')]),\n",
    "                    (merge, model, [('merged_file','in_file')]),\n",
    "                    \n",
    "                    (model, split, [('out_t','in_file')]),\n",
    "                    (split, cluster, [('out_files','in_file')]),\n",
    "                    (cluster, get_peaks, [('index_file','clusters_file')]),\n",
    "                    (split, get_peaks, [('out_files','stat_file')]),\n",
    "                    (cluster, get_betas ,[('index_file','cluster_index_file')]),\n",
    "                    (merge, get_betas, [('merged_file','sample_betas')]),\n",
    "                    \n",
    "                    (get_peaks, datasink, [('cluster_info_file','affect_cluster_stats')]),\n",
    "                    (get_betas, datasink, [('extracted_betas_csv','affect_cluster_betas')]),\n",
    "                    (model, datasink, [('out_p','pval_files'),\n",
    "                                       ('out_t','tstat_files')]),\n",
    "                    (cluster, datasink, [('index_file','clusters_file')])\n",
    "                   ])\n",
    "\n",
    "grouplevel.base_dir = wkflow_dir\n",
    "#grouplevel.write_graph(graph2use='flat')\n",
    "grouplevel.run('MultiProc', plugin_args={'n_procs': 2})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv\n",
    "from scipy.stats import spearmanr\n",
    "from numpy import round\n",
    "file = '/Users/catcamacho/Box/SNAP/BABIES/BABIES_asl/results/5predictors.csv'\n",
    "data=read_csv(file,index_col=None)\n",
    "data.head()\n",
    "\n",
    "rho, pval = spearmanr(data.values,nan_policy='omit')\n",
    "print(data.columns)\n",
    "print(round(rho,decimals=3))\n",
    "print(round(pval,decimals=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the upper percentage of t-stats with respect to age\n",
    "from nibabel import load\n",
    "from numpy import nanpercentile\n",
    "\n",
    "file = '/Users/catcamacho/Box/SNAP/BABIES/BABIES_asl/proc/asl_group_age/tstat_files/vol0000.nii.gz'\n",
    "\n",
    "img =load(file)\n",
    "data = img.get_data()\n",
    "data = data[data>0]\n",
    "\n",
    "print(nanpercentile(data, 95,interpolation='linear'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
