{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCASL processing\n",
    "\n",
    "The purpose of this notebook is to: \n",
    "1. transform infant 3D pcASL data into a common space for analysis (preprocflow)\n",
    "2. quantify voxelwise cerebral bloodflow (cbfprocflow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nipype.interfaces.utility import Function, IdentityInterface\n",
    "from nipype.interfaces.io import SelectFiles, DataSink\n",
    "from nipype.pipeline.engine import Workflow, Node, MapNode\n",
    "from nibabel import load, Nifti1Image\n",
    "\n",
    "from nipype.interfaces.slicer.registration import brainsresample\n",
    "from nipype.algorithms.misc import Gunzip\n",
    "from nipype.interfaces.freesurfer.preprocess import MRIConvert, ApplyVolTransform, MNIBiasCorrection\n",
    "from nipype.interfaces.fsl.utils import Reorient2Std\n",
    "from nipype.interfaces.fsl.maths import ApplyMask\n",
    "from nipype.interfaces.fsl.preprocess import FLIRT\n",
    "from nipype.interfaces.freesurfer.model import Binarize\n",
    "from nipype.interfaces.spm.preprocess import Smooth\n",
    "from nipype.interfaces.ants.registration import Registration\n",
    "from nipype.interfaces.ants.resampling import ApplyTransforms\n",
    "\n",
    "# MATLAB setup - Specify path to current SPM and the MATLAB's default mode\n",
    "from nipype.interfaces.matlab import MatlabCommand\n",
    "MatlabCommand.set_default_paths('~/spm12/toolbox')\n",
    "MatlabCommand.set_default_matlab_cmd(\"matlab -nodesktop -nosplash\")\n",
    "\n",
    "# FSL set up- change default file output type\n",
    "from nipype.interfaces.fsl import FSLCommand\n",
    "FSLCommand.set_default_output_type('NIFTI_GZ')\n",
    "\n",
    "#other study-specific variables\n",
    "project_home = '/Users/catcamacho/Box/SNAP/BABIES'\n",
    "raw_dir = project_home + '/raw'\n",
    "subjects_list = open(project_home + '/misc/subjects_asl.txt').read().splitlines()\n",
    "#subjects_list = ['1037','1033','115']\n",
    "output_dir = project_home + '/proc/asl_preproc'\n",
    "wkflow_dir = project_home + '/workflows'\n",
    "template = project_home + '/templates/T2w_BABIES_template_2mm.nii.gz'\n",
    "mask = project_home + '/templates/BABIES_gm_mask_2mm.nii.gz'\n",
    "t2_mask = project_home + '/templates/T2w_BABIES_template_2mm_mask.nii.gz'\n",
    "T1_file = project_home + '/templates/qT1_template_2mm.nii.gz' \n",
    "T1_vol = load(T1_file)\n",
    "T1_tissue = T1_vol.get_data()\n",
    "\n",
    "#Population specific variables for ASL\n",
    "nex_asl = 3 #number of excitations from the 3D ASL scan parameters\n",
    "inversion_efficiency = 0.8 #from GE\n",
    "background_supp_eff = 0.75 #from GE\n",
    "efficiency = inversion_efficiency * background_supp_eff # from GE\n",
    "T1_blood = 1.6 #T1 of blood in seconds(1.6s at 3T and 1.4s at 1.5T)\n",
    "sat_time = 2 #in seconds, from GE\n",
    "partition_coeff = 0.9 #whole brain average in ml/g\n",
    "scaling_factor = 32 #scaling factor, can be taken from PW dicom header at position 0043,107f (corresponds to #coils?)\n",
    "postlabel_delay = 1.525 #post label delay in seconds\n",
    "labeling_time = 1.450 #labeling time in seconds\n",
    "TR = 4.844 #repetition time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## File handling nodes\n",
    "\n",
    "# Select subjects\n",
    "infosource = Node(IdentityInterface(fields=['subjid', 'volume']),\n",
    "                  name='infosource')\n",
    "infosource.iterables = [('subjid', subjects_list)]\n",
    "\n",
    "\n",
    "# SelectFiles\n",
    "templates = {'pw_volume': raw_dir + '/{subjid}-BABIES/pw.nii.gz',\n",
    "             'anat_volume': raw_dir + '/{subjid}-BABIES/skullstripped_anat.nii.gz',\n",
    "             'pd_volume': raw_dir + '/{subjid}-BABIES/pd.nii.gz'}\n",
    "selectfiles = Node(SelectFiles(templates), name='selectfiles')\n",
    "\n",
    "\n",
    "# Datasink\n",
    "datasink = Node(DataSink(), name='datasink')\n",
    "datasink.inputs.base_directory = output_dir\n",
    "datasink.inputs.container = output_dir\n",
    "# DataSink output substitutions (for ease of folder naming)\n",
    "substitutions = [('_subjid_', ''),\n",
    "                ('volume_',''),\n",
    "                ('_reoriented',''),\n",
    "                ('_warped','')]\n",
    "datasink.inputs.substitutions = substitutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## File Processing nodes\n",
    "\n",
    "# convert files to nifti\n",
    "mri_convert = Node(MRIConvert(out_type='niigz',\n",
    "                              conform_size=2,\n",
    "                              crop_size=(128, 128, 128), \n",
    "                             ),\n",
    "                   name='mri_convert')\n",
    "\n",
    "# reorient data for consistency\n",
    "reorient_anat = Node(Reorient2Std(),\n",
    "                     name='reorient_anat')\n",
    "\n",
    "# reorient data for consistency\n",
    "reorient_pd = Node(Reorient2Std(),\n",
    "                   name='reorient_pd')\n",
    "\n",
    "# reorient data for consistency\n",
    "reorient_pw = Node(Reorient2Std(),\n",
    "                   name='reorient_pw')\n",
    "\n",
    "# N3 bias correction using MINC tools\n",
    "nu_correct_pd = Node(MNIBiasCorrection(iterations=4, \n",
    "                                       no_rescale=True, \n",
    "                                       out_file='pd_nu.nii.gz'), \n",
    "                     name='nu_correct_pd')\n",
    "\n",
    "nu_correct_pw = Node(MNIBiasCorrection(iterations=4, \n",
    "                                       no_rescale=True, \n",
    "                                       out_file='pw_nu.nii.gz'), \n",
    "                     name='nu_correct_pw')\n",
    "\n",
    "# register PW to anat\n",
    "coregT2 = Node(Registration(args='--float',\n",
    "                            collapse_output_transforms=True,\n",
    "                            initial_moving_transform_com=True,\n",
    "                            num_threads=1,\n",
    "                            output_inverse_warped_image=True,\n",
    "                            output_warped_image=True,\n",
    "                            sigma_units=['vox']*2,\n",
    "                            transforms=['Rigid', 'Affine'],\n",
    "                            terminal_output='file',\n",
    "                            winsorize_lower_quantile=0.005,\n",
    "                            winsorize_upper_quantile=0.995,\n",
    "                            convergence_threshold=[1e-06],\n",
    "                            convergence_window_size=[10],\n",
    "                            metric=['Mattes', 'Mattes'],\n",
    "                            metric_weight=[1.0]*2,\n",
    "                            number_of_iterations=[[100, 75, 50],\n",
    "                                                  [100, 75, 50]],\n",
    "                            radius_or_number_of_bins=[32, 32],\n",
    "                            sampling_percentage=[0.25, 0.25],\n",
    "                            sampling_strategy=['Regular',\n",
    "                                               'Regular'],\n",
    "                            shrink_factors=[[4, 2, 1]]*2,\n",
    "                            smoothing_sigmas=[[2, 1, 0]]*2,\n",
    "                            transform_parameters=[(0.1,),\n",
    "                                                  (0.1,)],\n",
    "                            use_histogram_matching=False,\n",
    "                            write_composite_transform=True),\n",
    "               name='coregT2')\n",
    "\n",
    "\n",
    "applyxform = Node(ApplyTransforms(), name = 'applyxform')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data QC nodes\n",
    "def create_coreg_plot(epi,anat):\n",
    "    '''This function creates plots of the CBF data overlaid on the \n",
    "    participant's anatomical image for quality control purposes'''\n",
    "    import os\n",
    "    from nipype import config, logging\n",
    "    config.enable_debug_mode()\n",
    "    logging.update_logging(config)\n",
    "    from nilearn import plotting\n",
    "    \n",
    "    coreg_filename='coregistration.png'\n",
    "    display = plotting.plot_anat(epi, display_mode='ortho',\n",
    "                                 draw_cross=False,\n",
    "                                 title = 'coregistration to anatomy')\n",
    "    display.add_edges(anat)\n",
    "    display.savefig(coreg_filename) \n",
    "    display.close()\n",
    "    coreg_file = os.path.abspath(coreg_filename)\n",
    "    \n",
    "    return(coreg_file)\n",
    "\n",
    "make_coreg_img = Node(name='make_coreg_img',\n",
    "                      interface=Function(input_names=['epi','anat'],\n",
    "                                         output_names=['coreg_file'],\n",
    "                                         function=create_coreg_plot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a flow for preprocessing anat + asl volumes \n",
    "preprocflow = Workflow(name='preprocflow')\n",
    "\n",
    "# Connect all components of the preprocessing workflow\n",
    "preprocflow.connect([(infosource, selectfiles, [('subjid', 'subjid')]),\n",
    "                     (selectfiles, mri_convert, [('anat_volume', 'in_file')]),\n",
    "                     (mri_convert, reorient_anat, [('out_file', 'in_file')]),    \n",
    "                     (selectfiles, reorient_pw, [('pw_volume', 'in_file')]), \n",
    "                     (selectfiles, reorient_pd, [('pd_volume', 'in_file')]),\n",
    "                     (reorient_anat, coregT2, [('out_file', 'fixed_image')]),\n",
    "                     (reorient_pw, nu_correct_pw, [('out_file','in_file')]),\n",
    "                     (nu_correct_pw, coregT2, [('out_file', 'moving_image')]),\n",
    "                     (coregT2, applyxform, [('composite_transform','transforms')]),\n",
    "                     (reorient_anat, applyxform, [('out_file','reference_image')]),\n",
    "                     (reorient_pd, nu_correct_pd, [('out_file','in_file')]),\n",
    "                     (nu_correct_pd, applyxform, [('out_file','input_image')]),\n",
    "                     (coregT2, make_coreg_img, [('warped_image','epi')]),\n",
    "                     (reorient_anat, make_coreg_img, [('out_file','anat')]),\n",
    "                     \n",
    "                     (make_coreg_img, datasink, [('coreg_file','coreg_check')]),\n",
    "                     (applyxform, datasink, [('output_image','warped_pd')]),\n",
    "                     (coregT2, datasink, [('warped_image','warped_pw')]),\n",
    "                     (reorient_anat, datasink, [('out_file', 'reorient_anat')])\n",
    "                    ])\n",
    "preprocflow.base_dir = wkflow_dir\n",
    "preprocflow.write_graph(graph2use='flat')\n",
    "preprocflow.run('MultiProc', plugin_args={'n_procs': 2})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## File handling nodes for CBF proc\n",
    "\n",
    "# Select subjects\n",
    "cbfinfosource = Node(IdentityInterface(fields=['subjid']),\n",
    "                  name='cbfinfosource')\n",
    "cbfinfosource.iterables = [('subjid', subjects_list)]\n",
    "\n",
    "\n",
    "# SelectFiles\n",
    "templates = {'pw_volume': output_dir + '/warped_pw/{subjid}/transform_Warped.nii.gz',\n",
    "            'pd_volume': output_dir + '/warped_pd/{subjid}/pd_nu_trans.nii.gz',\n",
    "            'anat_volume': output_dir + '/reorient_anat/{subjid}/skullstripped_anat_out.nii.gz'}\n",
    "cbfselectfiles = Node(SelectFiles(templates), name='cbfselectfiles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Custom functions\n",
    "\n",
    "#quantify CBF from PW volume (Alsop MRIM 2015 method)\n",
    "def quantify_cbf_alsop(pw_volume,pd_volume,sat_time,postlabel_delay,T1_blood,labeling_time,efficiency,\n",
    "                       partition_coeff,TR,T1_tissue,scaling_factor,nex_asl, mask):\n",
    "    '''This function quantifies regional cerebral blood flow in accordance with the \n",
    "    recommendations in Alsop et al., 2015 and with modifications as recommended by \n",
    "    the sequence manufacturer (GE).'''\n",
    "    import os\n",
    "    import nibabel as nib\n",
    "    from numpy import exp\n",
    "    from nipype import config, logging\n",
    "    config.enable_debug_mode()\n",
    "    logging.update_logging(config)\n",
    "    \n",
    "    # set variables\n",
    "    mask_nifti1 = nib.load(mask)\n",
    "    mask_data = mask_nifti1.get_data()\n",
    "    mask_data = mask_data.astype(float)\n",
    "    \n",
    "    T1_tissue = T1_tissue*mask_data\n",
    "    pw_nifti1 = nib.load(pw_volume)\n",
    "    pw_data = pw_nifti1.get_data()\n",
    "    pw_data = pw_data.astype(float)*mask_data\n",
    "    pd_nifti1 = nib.load(pd_volume)\n",
    "    pd_data = pd_nifti1.get_data()\n",
    "    pd_data = pd_data.astype(float)*mask_data\n",
    "    conversion = 6000 #to convert values from mL/g/s to mL/100g/min\n",
    "    pd_factor = 1/(1-exp((-1*TR)/T1_tissue))\n",
    "    \n",
    "    cbf_numerator = conversion*partition_coeff*pw_data*exp(postlabel_delay/T1_blood)\n",
    "    cbf_denominator = sat_time*efficiency*T1_blood*scaling_factor*nex_asl*pd_data*pd_factor*(1-exp((-1*labeling_time)/T1_blood))\n",
    "    cbf_data = cbf_numerator/cbf_denominator\n",
    "    \n",
    "    cbf_volume = nib.Nifti1Image(cbf_data, pw_nifti1.affine)\n",
    "    nib.save(cbf_volume, 'alsop_cbf.nii')\n",
    "    cbf_path = os.path.abspath('alsop_cbf.nii')\n",
    "    return cbf_path\n",
    "\n",
    "quant_cbf_alsop = Node(name='quant_cbf_alsop',\n",
    "                interface=Function(input_names=['pw_volume','pd_volume',\n",
    "                                                'sat_time','postlabel_delay',\n",
    "                                                'T1_blood','labeling_time',\n",
    "                                                'efficiency','partition_coeff',\n",
    "                                                'TR','T1_tissue','scaling_factor',\n",
    "                                                'nex_asl','mask'],\n",
    "                                  output_names=['cbf_volume'],\n",
    "                                  function=quantify_cbf_alsop))\n",
    "quant_cbf_alsop.inputs.sat_time=sat_time\n",
    "quant_cbf_alsop.inputs.postlabel_delay=postlabel_delay\n",
    "quant_cbf_alsop.inputs.T1_blood=T1_blood\n",
    "quant_cbf_alsop.inputs.labeling_time=labeling_time\n",
    "quant_cbf_alsop.inputs.efficiency=efficiency\n",
    "quant_cbf_alsop.inputs.partition_coeff=partition_coeff\n",
    "quant_cbf_alsop.inputs.TR=TR\n",
    "quant_cbf_alsop.inputs.T1_tissue=T1_tissue\n",
    "quant_cbf_alsop.inputs.scaling_factor=scaling_factor\n",
    "quant_cbf_alsop.inputs.nex_asl=nex_asl\n",
    "quant_cbf_alsop.inputs.mask=t2_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Normalizing data for first and second level analysis\n",
    "smooth = Node(Smooth(fwhm=[4,4,4], \n",
    "                     implicit_masking=True), \n",
    "              name='smooth')\n",
    "\n",
    "# register PW to anat\n",
    "reg2temp = Node(Registration(args='--float',\n",
    "                             collapse_output_transforms=True,\n",
    "                             initial_moving_transform_com=True,\n",
    "                             num_threads=1,\n",
    "                             output_inverse_warped_image=True,\n",
    "                             output_warped_image=True,\n",
    "                             sigma_units=['vox']*2,\n",
    "                             transforms=['Rigid', 'Affine'],\n",
    "                             terminal_output='file',\n",
    "                             winsorize_lower_quantile=0.005,\n",
    "                             winsorize_upper_quantile=0.995,\n",
    "                             convergence_threshold=[1e-06],\n",
    "                             convergence_window_size=[10],\n",
    "                             metric=['Mattes', 'Mattes', 'CC'],\n",
    "                             metric_weight=[1.0]*3,\n",
    "                             number_of_iterations=[[100, 75, 50],\n",
    "                                                   [100, 75, 50]],\n",
    "                             radius_or_number_of_bins=[32, 32],\n",
    "                             sampling_percentage=[0.25, 0.25],\n",
    "                             sampling_strategy=['Regular',\n",
    "                                                'Regular'],\n",
    "                             shrink_factors=[[4, 2, 1]]*2,\n",
    "                             smoothing_sigmas=[[2, 1, 0]]*2,\n",
    "                             transform_parameters=[(0.1,),\n",
    "                                                   (0.1,)],\n",
    "                             use_histogram_matching=False,\n",
    "                             write_composite_transform=True, \n",
    "                             fixed_image=template),\n",
    "                name='reg2temp')\n",
    "\n",
    "applyxform_pw = Node(ApplyTransforms(reference_image=template), \n",
    "                     name = 'applyxform_pw')\n",
    "applyxform_pd = Node(ApplyTransforms(reference_image=template), \n",
    "                     name = 'applyxform_pd')\n",
    "\n",
    "apply_mask = Node(ApplyMask(mask_file=mask),name='apply_mask')\n",
    "\n",
    "# Check template registration\n",
    "check_template_coreg = Node(name='check_template_coreg',\n",
    "                            interface=Function(input_names=['epi','anat'],\n",
    "                                               output_names=['coreg_file'],\n",
    "                                               function=create_coreg_plot))\n",
    "check_template_coreg.inputs.anat=template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a flow for quantifying CBF and warping to MNI space.\n",
    "cbfprocflow = Workflow(name='cbfprocflow')\n",
    "\n",
    "# connect the nodes\n",
    "cbfprocflow.connect([(cbfinfosource, cbfselectfiles, [('subjid', 'subjid')]),\n",
    "                     (cbfselectfiles, reg2temp, [('anat_volume', 'moving_image')]),\n",
    "                     (cbfselectfiles, applyxform_pw, [('pw_volume','input_image')]),\n",
    "                     (cbfselectfiles, applyxform_pd, [('pd_volume','input_image')]),\n",
    "                     (reg2temp, applyxform_pw, [('composite_transform','transforms')]),\n",
    "                     (reg2temp, applyxform_pd, [('composite_transform','transforms')]),\n",
    "                     (applyxform_pw, quant_cbf_alsop, [('output_image', 'pw_volume')]),\n",
    "                     (applyxform_pd, quant_cbf_alsop, [('output_image', 'pd_volume')]),\n",
    "                     (quant_cbf_alsop, smooth, [('cbf_volume','in_files')]), \n",
    "                     (smooth,apply_mask, [('smoothed_files','in_file')]),\n",
    "                     (apply_mask, check_template_coreg, [('out_file','epi')]),\n",
    "                     \n",
    "                     (reg2temp, datasink, [('warped_image','processed_t2')]),\n",
    "                     (check_template_coreg, datasink, [('coreg_file','template_coreg')]),\n",
    "                     (apply_mask, datasink, [('out_file', 'cbf_volume')])\n",
    "                    ]),\n",
    "cbfprocflow.base_dir = wkflow_dir\n",
    "cbfprocflow.write_graph(graph2use='flat')\n",
    "cbfprocflow.run('MultiProc', plugin_args={'n_procs': 2})\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
